{"nbformat_minor": 1, "cells": [{"execution_count": 1, "cell_type": "code", "source": "from pyspark.mllib.regression import LabeledPoint\nfrom pyspark.mllib.regression import LinearRegressionModel\nfrom pyspark.mllib.regression import LinearRegressionWithSGD\nfrom pyspark.mllib.linalg import Vectors\nfrom pyspark.mllib.feature import StandardScaler", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Starting Spark application\n"}, {"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<table>\n<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>1</td><td>application_1481496952186_0006</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://hn1-mysia.pxdglzulbree1lxqjdfwz4hrfb.qx.internal.cloudapp.net:8088/proxy/application_1481496952186_0006/\">Link</a></td><td><a target=\"_blank\" href=\"http://10.0.0.4:30060/node/containerlogs/container_1481496952186_0006_01_000001/livy\">Link</a></td><td>\u2714</td></tr></table>"}, "metadata": {}}, {"output_type": "stream", "name": "stdout", "text": "SparkContext available as 'sc'.\nHiveContext available as 'sqlContext'.\n"}], "metadata": {"collapsed": false}}, {"execution_count": 2, "cell_type": "code", "source": "def parsePoint(line):\n    values = [float(x) for x in line.split(',')[0:7]]\n    return LabeledPoint(values[0], values[1:])\ninput = sc.textFile(\"wasb:///autos.csv\")\nfeaturevector = input.map(lambda line : parsePoint(line)).persist()", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 3, "cell_type": "code", "source": "labels = featurevector.map(lambda x: x.label)\nfeatures = featurevector.map(lambda x: x.features)\nscaler = StandardScaler().fit(features)\nscaledData = scaler.transform(features)\nnewfeatures = labels.zip(scaledData)\nallset = newfeatures.map(lambda line: LabeledPoint(line[0], line[1]))", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 4, "cell_type": "code", "source": "training, test = allset.randomSplit(weights=[0.7, 0.3], seed=1)", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 5, "cell_type": "code", "source": "numIterations = 100\nstepSize = 0.001", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 6, "cell_type": "code", "source": "algorithm = LinearRegressionWithSGD.train(training, iterations=numIterations, step=stepSize, intercept=True)", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 7, "cell_type": "code", "source": "valuesAndPreds = test.map(lambda p: (p.label, algorithm.predict(p.features)))\nvaluesAndPreds.take(20)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "[(18.0, 22.128269194125018), (18.0, 22.0312203809492), (15.0, 22.025508507968652), (14.0, 21.87321961819093), (14.0, 22.055806781122165), (15.0, 21.882771171766098), (10.0, 22.592864010531148), (28.0, 22.535309934809128), (25.0, 22.374082240371724), (16.0, 22.698173356590914), (17.0, 22.682959060741549), (19.0, 22.669276631439665), (14.0, 22.484461180400736), (12.0, 22.496700249536605), (13.0, 22.525151818370045), (18.0, 22.546630266507471), (30.0, 22.400811906735715), (24.0, 22.816716210033032), (14.0, 22.7762419285242), (15.0, 22.905988531326884)]"}], "metadata": {"collapsed": false}}, {"execution_count": 8, "cell_type": "code", "source": "MSE = valuesAndPreds.map(lambda (v, p): (v - p)**2).reduce(lambda x, y: x + y) / valuesAndPreds.count()\nprint(\"Mean Squared Error = \" + str(MSE))", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Mean Squared Error = 53.8697651551"}], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "", "outputs": [], "metadata": {"collapsed": true}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "PySpark", "name": "pysparkkernel", "language": ""}, "language_info": {"mimetype": "text/x-python", "pygments_lexer": "python2", "name": "pyspark", "codemirror_mode": {"version": 2, "name": "python"}}}}